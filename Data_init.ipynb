{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c11ebcd3-10b9-4f38-beec-937d098b6609",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.6.tar.gz (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.6/84.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from kaggle) (2023.11.17)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from kaggle) (4.66.1)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/lib/python3.10/site-packages (from kaggle) (1.26.18)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.10/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->kaggle) (3.6)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.6-py3-none-any.whl size=111943 sha256=175768ebc3e5808904ee636a54173358afbf1fefad159a44b65c10e2849920be\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/53/34/8c/8ca3450d17206d9e37e1ee3aeb47cbb2873d22a9e0c60eb137\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.6.6 python-slugify-8.0.4 text-unidecode-1.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.16.3-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\n",
      "Collecting appdirs>=1.4.3 (from wandb)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Installing collected packages: appdirs, setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed appdirs-1.4.4 docker-pycreds-0.4.0 sentry-sdk-1.40.6 setproctitle-1.3.3 wandb-0.16.3\n"
     ]
    }
   ],
   "source": [
    "#VM DATASET INIT SET UP\n",
    "!pip install kaggle\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from torchvision.transforms import v2\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "#your api key\n",
    "api_key = {\"username\":\"ishag7\",\n",
    "           \"key\":\"73dac2ca88ce68fa7aaf9390f36326a5\"}\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = \"ishag7\"\n",
    "os.environ['KAGGLE_KEY'] = \"73dac2ca88ce68fa7aaf9390f36326a5\"\n",
    "\n",
    "#uses pathlib Path\n",
    "kaggle_path = Path('/home/jupyter/.kaggle')\n",
    "\n",
    "#make kaggle dir\n",
    "os.makedirs(kaggle_path)\n",
    "\n",
    "#opens file and dumps python dict to json object\n",
    "with open (kaggle_path/'kaggle.json', 'w') as handl:\n",
    "           json.dump(api_key,handl)\n",
    "#change dir permissions\n",
    "os.chmod(kaggle_path/'kaggle.json', 700)\n",
    "#import kaggle api\n",
    "import kaggle as kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "#set up api and authentication wit json token\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "#download train and test files\n",
    "kaggle.api.dataset_download_files('birdy654/cifake-real-and-ai-generated-synthetic-images', unzip = True)\n",
    "\n",
    "!pip install wandb\n",
    "import random as random\n",
    "random.seed(420)\n",
    "val_fake = random.sample(os.listdir('/home/jupyter/test/FAKE/'), 5000)\n",
    "val_real = random.sample(os.listdir('/home/jupyter/test/REAL/'), 5000)\n",
    "pd.DataFrame(val_fake).to_csv('./val_fake_filenames.csv', header = None, index = None)\n",
    "pd.DataFrame(val_real).to_csv('./val_real_filenames.csv', header = None, index = None)\n",
    "os.makedirs('/home/jupyter/val')\n",
    "os.makedirs('/home/jupyter/val/REAL')\n",
    "os.makedirs('/home/jupyter/val/FAKE')\n",
    "for i in range(0, 5000):\n",
    "    os.rename('/home/jupyter/test/FAKE/' + val_fake[i], '/home/jupyter/val/FAKE/' + val_fake[i])\n",
    "    os.rename('/home/jupyter/test/REAL/' + val_real[i], '/home/jupyter/val/REAL/' + val_real[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "609680b8-71ae-492d-9af8-fa21c61ee247",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.io import read_image\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchvision.transforms import v2\n",
    "import torch.nn.functional as F\n",
    "import wandb as wandb\n",
    "\n",
    "# Borrowed with modifications from CSE 599G Spring 2023\n",
    "def check_accuracy_part34(loader, model, device, dtype=torch.float32, num_samples = 10000):\n",
    " #   print(\"Starting check_accuracy_part34\")\n",
    "    num_correct = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    s_fn = nn.Sigmoid()\n",
    "    with torch.no_grad():\n",
    "        for t, (x, y) in enumerate(loader):\n",
    "          #  print(\"Iteration of internal loop in accuracy checker\")\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=dtype)\n",
    "          #  print(\"Finished converting x and y to right device. Calculating scores\")\n",
    "            score = model(x)\n",
    "            loss = criterion(score, y.reshape([-1,1 ]))\n",
    "            num_correct += (torch.round(s_fn(score)) == y.reshape([-1,1])).float().sum()\n",
    "          #  print(\"Finished calculating scores. \")\n",
    "          #  print(\"Finished calculating scores & num_correct, num_samples\")\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc, loss\n",
    "\n",
    "\n",
    "# Borrowed with modifications from CSE 599G Spring 2023\n",
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return flatten(x)\n",
    "\n",
    "# Borrowed with modifications from CSE 599G Spring 2023\n",
    "def train_part34(model, optimizer, device, loader, val_loader=None, epochs=1, dtype=torch.float32, print_every=50):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "\n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "\n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    for e in range(epochs):\n",
    "        print(\"epoch \", e)\n",
    "        # unpacking train_loader is the bottleneck; saving it as an iterable\n",
    "        # to memory before the loop doesn't help\n",
    "        for t, (x, y) in enumerate(loader):\n",
    "\n",
    "           # print(\"Putting model in training mode\")\n",
    "            model.train()  # put model to training mode\n",
    "           # print(\"Converting X and y to correct devices and data types\")\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "           # print(\"X, y conversion complete\")\n",
    "\n",
    "           # print(\"Generating scores\")\n",
    "            score = model(x)\n",
    "            #print(\"Done calculating score. Calculating loss...\")\n",
    "            loss = criterion(score, y.unsqueeze(1).float())            \n",
    "            #print(\"Calculated loss. Zeroing out gradients...\")\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "           # print(\"Zeroed out gradients. Starting backward pass...\")\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "           # print(\"Completed backward pass. Making optimizer step...\")\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0 and val_loader != None:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                val_acc,val_loss = check_accuracy_part34(val_loader, model, device)\n",
    "                wandb.log({\"acc\": val_acc, \n",
    "                           \"train_loss\": loss,\n",
    "                           \"val_loss\": val_loss})\n",
    "\n",
    "def main(data_dir_path = \"/home/jupyter/\",\n",
    "         batch_size = 128, num_workers = 2, print_every = 50):\n",
    "    \n",
    "    print(\"Setting torch to run on GPU if available\")\n",
    "\n",
    "    USE_GPU = True\n",
    "    dtype = torch.float32 \n",
    "\n",
    "    if USE_GPU and torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "\n",
    "    # Constant to control how frequently we print train loss.\n",
    "    print_every = 50\n",
    "    print('using device:', device)\n",
    "\n",
    "    print(\"Setting up transforms to apply to image data...\")\n",
    "    transforms = v2.Compose([\n",
    "    v2.ToImagePIL(),  # Convert to tensor, only needed if you had a PIL image\n",
    "    v2.ToDtype(torch.uint8),  # optional, most input are already uint8 at this point\n",
    "    v2.ToTensor(),\n",
    "    #v2.Resize((128,128)),\n",
    "    #v2.RandomResizedCrop(size=(128, 128), scale = (0.08, 1.0), antialias=True),  # Or Resize(antialias=True)\n",
    "    #v2.ToDtype(torch.float32, scale=True),  # Normalize expects float input\n",
    "])\n",
    "    print(\"Complete.\")\n",
    "\n",
    "    data_dir = data_dir_path\n",
    "\n",
    "    print(\"Data directory is set to: \", data_dir)\n",
    "\n",
    "    print(\"Setting up ImageFolder objects for train, val, test...\")\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root=data_dir+'/train/', transform=transforms)\n",
    "    print(\"Train complete\")\n",
    "    val_dataset = datasets.ImageFolder(root=data_dir+'/val', transform=transforms)\n",
    "    print(\"Val complete\")\n",
    "    test_dataset = datasets.ImageFolder(root=data_dir+'/test/', transform=transforms)\n",
    "    print(\"Test complete\")\n",
    "\n",
    "    print(\"Now setting up loaders linked to those dataset objects:\")\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=num_workers,\n",
    "                                            shuffle = True)\n",
    "\n",
    "    print(\"Train loader complete\")\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=num_workers,\n",
    "                                            shuffle = True)\n",
    "\n",
    "    print(\"Val loader complete\")\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            num_workers=num_workers,\n",
    "                                             shuffle = True)\n",
    "\n",
    "    print(\"Test loader complete\")\n",
    "\n",
    "\n",
    "\n",
    "    channel_1 = 32\n",
    "    channel_2 = 32\n",
    "\n",
    "    print(\"Constructing model...\")\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(3, channel_1, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "        nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "        Flatten(),\n",
    "        # three layers of 64 rectified linear units per Bird, Lotfi (2023)\n",
    "        nn.Linear(channel_2 * 32 * 32, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64,1),\n",
    "    )\n",
    "    for rate in [1e-3, 1e-4, 1e-5, 1e-6]:\n",
    "        for l2reg in [0.1, 0.01, 0.001, 0.0001]:\n",
    "            wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=\"ADAM_runs\",\n",
    "            # track hyperparameters and run metadata\n",
    "            config={\n",
    "            \"learning_rate\": rate,\n",
    "            \"l2reg\": l2reg,\n",
    "            \"epochs\": 5,\n",
    "            \"optimizier\": \"ADAM\"}\n",
    "            )\n",
    "            optimizer = optim.Adam(model.parameters(),\n",
    "                                   lr = rate,\n",
    "                                   weight_decay = l2reg)\n",
    "            train_part34(model, optimizer, device, train_loader, val_loader, epochs=3) \n",
    "            wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c74aede6-c63e-497f-96d4-005a4e8a47ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting torch to run on GPU if available\n",
      "using device: cuda\n",
      "Setting up transforms to apply to image data...\n",
      "Complete.\n",
      "Data directory is set to:  /home/jupyter/\n",
      "Setting up ImageFolder objects for train, val, test...\n",
      "Train complete\n",
      "Val complete\n",
      "Test complete\n",
      "Now setting up loaders linked to those dataset objects:\n",
      "Train loader complete\n",
      "Val loader complete\n",
      "Test loader complete\n",
      "Constructing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /home/jupyter/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/wandb/run-20240302_002346-1jtumwgw</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cse599-proj-ai-img-detection/ADAM_runs/runs/1jtumwgw' target=\"_blank\">quiet-salad-2</a></strong> to <a href='https://wandb.ai/cse599-proj-ai-img-detection/ADAM_runs' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cse599-proj-ai-img-detection/ADAM_runs' target=\"_blank\">https://wandb.ai/cse599-proj-ai-img-detection/ADAM_runs</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cse599-proj-ai-img-detection/ADAM_runs/runs/1jtumwgw' target=\"_blank\">https://wandb.ai/cse599-proj-ai-img-detection/ADAM_runs/runs/1jtumwgw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "Iteration 0, loss = 0.6910\n",
      "Got 5886 / 10000 correct (58.86)\n",
      "Iteration 50, loss = 0.6142\n",
      "Got 6501 / 10000 correct (65.01)\n",
      "Iteration 100, loss = 0.5701\n",
      "Got 7164 / 10000 correct (71.64)\n",
      "Iteration 150, loss = 0.5493\n",
      "Got 7739 / 10000 correct (77.39)\n",
      "Iteration 200, loss = 0.5738\n",
      "Got 7678 / 10000 correct (76.78)\n",
      "Iteration 250, loss = 0.4625\n",
      "Got 7834 / 10000 correct (78.34)\n",
      "Iteration 300, loss = 0.4471\n",
      "Got 7947 / 10000 correct (79.47)\n",
      "Iteration 350, loss = 0.4853\n",
      "Got 7868 / 10000 correct (78.68)\n",
      "Iteration 400, loss = 0.4959\n",
      "Got 7634 / 10000 correct (76.34)\n",
      "Iteration 450, loss = 0.5082\n",
      "Got 7524 / 10000 correct (75.24)\n",
      "Iteration 500, loss = 0.4555\n",
      "Got 7850 / 10000 correct (78.50)\n",
      "Iteration 550, loss = 0.4885\n",
      "Got 7895 / 10000 correct (78.95)\n",
      "Iteration 600, loss = 0.4246\n",
      "Got 7920 / 10000 correct (79.20)\n",
      "Iteration 650, loss = 0.5056\n",
      "Got 7923 / 10000 correct (79.23)\n",
      "Iteration 700, loss = 0.5268\n",
      "Got 7865 / 10000 correct (78.65)\n",
      "Iteration 750, loss = 0.4972\n",
      "Got 7962 / 10000 correct (79.62)\n",
      "epoch  1\n",
      "Iteration 0, loss = 0.4859\n",
      "Got 7923 / 10000 correct (79.23)\n",
      "Iteration 50, loss = 0.4560\n",
      "Got 7897 / 10000 correct (78.97)\n",
      "Iteration 100, loss = 0.4026\n",
      "Got 7860 / 10000 correct (78.60)\n",
      "Iteration 150, loss = 0.4655\n",
      "Got 7768 / 10000 correct (77.68)\n",
      "Iteration 200, loss = 0.4584\n",
      "Got 7919 / 10000 correct (79.19)\n",
      "Iteration 250, loss = 0.4556\n",
      "Got 7939 / 10000 correct (79.39)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 195\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(data_dir_path, batch_size, num_workers, print_every)\u001b[0m\n\u001b[1;32m    182\u001b[0m wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# set the wandb project where this run will be logged\u001b[39;00m\n\u001b[1;32m    184\u001b[0m project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADAM_runs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizier\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADAM\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m    193\u001b[0m                        lr \u001b[38;5;241m=\u001b[39m rate,\n\u001b[1;32m    194\u001b[0m                        weight_decay \u001b[38;5;241m=\u001b[39m l2reg)\n\u001b[0;32m--> 195\u001b[0m \u001b[43mtrain_part34\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m    196\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
      "Cell \u001b[0;32mIn[25], line 60\u001b[0m, in \u001b[0;36mtrain_part34\u001b[0;34m(model, optimizer, device, loader, val_loader, epochs, dtype, print_every)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# unpacking train_loader is the bottleneck; saving it as an iterable\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# to memory before the loop doesn't help\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t, (x, y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m    \u001b[38;5;66;03m# print(\"Putting model in training mode\")\u001b[39;00m\n\u001b[1;32m     63\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# put model to training mode\u001b[39;00m\n\u001b[1;32m     64\u001b[0m    \u001b[38;5;66;03m# print(\"Converting X and y to correct devices and data types\")\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m116",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m116"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
